{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcAzm+dCQy5zvORFemMT1Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d7f0f9c7200149ca84ddd3f3ef344a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Image Path:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ab8bb51d4c5b4b87a891b13f8538059a",
            "placeholder": "Enter image path",
            "style": "IPY_MODEL_1f620902276049ef9e6b6a4d8ba0ae01",
            "value": "flyer.jpg"
          }
        },
        "ab8bb51d4c5b4b87a891b13f8538059a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f620902276049ef9e6b6a4d8ba0ae01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c9e6e4276f24f0e8a0919d49a6b94b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Prompt:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_12db96cc4bae4009b8c5854fbe57ce5c",
            "placeholder": "Enter your prompt",
            "rows": null,
            "style": "IPY_MODEL_6cdd317dd09c45aebda6b42a369b3cc2",
            "value": "thoughts?"
          }
        },
        "12db96cc4bae4009b8c5854fbe57ce5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cdd317dd09c45aebda6b42a369b3cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "162dc4e4e2d3433292a8fd3113598d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Submit",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ee6ce9cbaf8e4ed0868e5cd0c49129d7",
            "style": "IPY_MODEL_e6bc6f38e1ae4ac9aecc174f54a95427",
            "tooltip": ""
          }
        },
        "ee6ce9cbaf8e4ed0868e5cd0c49129d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6bc6f38e1ae4ac9aecc174f54a95427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "8fbccf6b9020423b9f1627e634394fd1": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_51fdb434146c414dbfbc424e7a38f77b",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "WARNING: parsing_instruction is deprecated. Use complemental_formatting_instruction or content_guideline_instruction instead.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "IMAGE DESCR: # LEARN FRENCH\n",
                  "\n",
                  "## FRE 2200 FRENCH 3-001\n",
                  "\n",
                  "### SPRING 2025\n",
                  "\n",
                  "LAST BUT NOT LEAST COURSE TO MASTER\n",
                  "THE BASICS OF FRENCH LANGUAGE!\n",
                  "\n",
                  "TOPICS COVERED: SOCIAL AND\n",
                  "CULTURAL VALUES, IMMIGRATION,\n",
                  "THE ENVIRONMENT and more...\n",
                  "\n",
                  "\\+ MULTIMEDIA, MUSIC & A FRENCH FILM.\n",
                  "\n",
                  "### GATEWAY COURSE TO ALL UPPER-LEVEL FRENCH COURSES INCLUDING:\n",
                  "\n",
                  "- MINOR IN FRENCH\n",
                  "- MAJOR OR DOUBLE MAJOR IN WORLD\n",
                  "  LANGUAGES-FRENCH CONCENTRATION\n",
                  "\n",
                  "### WHO, WHEN, WHERE, HOW?\n",
                  "\n",
                  "MW 11:00AM- 12:15PM\n",
                  "SOC: 347\n",
                  "CRN: #13910\n",
                  "\n",
                  "### CONTACT INFO\n",
                  "\n",
                  "savonas@usf.edu\n",
                  "World Languages Department\n",
                  "\n",
                  "----\n",
                  "\n",
                  "UNIVERSITY of\n",
                  "SOUTH FLORIDA\n",
                  "College of Arts & Sciences\n",
                  "-----\n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.Markdown object>",
                  "text/markdown": "The provided text appears to be a course description for a French language class, FRE 2200, at the University of South Florida. Here are some thoughts based on the information:\n\n1. **Comprehensive curriculum**: The course covers a range of topics, including social and cultural values, immigration, and the environment, which suggests a well-rounded and engaging learning experience.\n2. **Multimedia and cultural elements**: The inclusion of multimedia, music, and a French film will likely make the course more enjoyable and help students connect with the language on a deeper level.\n3. **Importance of the course**: As a gateway course to upper-level French classes, this course seems crucial for students interested in pursuing a minor or major in French or World Languages with a French concentration.\n4. **Accessibility**: The course schedule (MW 11:00AM-12:15PM) and location (SOC: 347) are clearly stated, making it easy for students to plan their schedules.\n5. **Support and resources**: The contact information for the instructor (savonas@usf.edu) and the World Languages Department provides students with a clear point of contact for questions or concerns.\n6. **Institutional context**: The course is part of the University of South Florida's College of Arts & Sciences, which suggests that the university values language education and cultural diversity.\n\nOverall, the course seems to offer a solid foundation in French language and culture, with a good balance of academic and cultural content. It also appears to be well-supported by the university and the instructor, which can help students succeed in their language learning journey."
                },
                "metadata": {}
              }
            ]
          }
        },
        "51fdb434146c414dbfbc424e7a38f77b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f7d01c24e664f5b834fdd1ba6508969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Image Path:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_00b1c0c01cac44ea8d643bcc20705743",
            "placeholder": "Enter image path",
            "style": "IPY_MODEL_22701e243ea548fda5c241f80d5ee653",
            "value": "pickle.jpg"
          }
        },
        "00b1c0c01cac44ea8d643bcc20705743": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22701e243ea548fda5c241f80d5ee653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3e9adf926384589afa647bdf4e2eb36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Prompt:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b67314b67b3348e28ef8af13336c5c66",
            "placeholder": "Enter your prompt",
            "rows": null,
            "style": "IPY_MODEL_7e0a115c7f8a4810a8ab6e9b995715d8",
            "value": "idk what this is"
          }
        },
        "b67314b67b3348e28ef8af13336c5c66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e0a115c7f8a4810a8ab6e9b995715d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f38c83dc23e5415eb01de7d322813f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Homework",
              "Event",
              "Other"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Context:",
            "description_tooltip": null,
            "disabled": false,
            "index": 2,
            "layout": "IPY_MODEL_20d2261a8097417080c564f17294fe7c",
            "style": "IPY_MODEL_c4d4466814f84beca7accac38f38d96e"
          }
        },
        "20d2261a8097417080c564f17294fe7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d4466814f84beca7accac38f38d96e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "987b4b31983d4e8d8b97db82954bd373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Submit",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_779e73ba357c45ceb88627722001b0de",
            "style": "IPY_MODEL_40f45d07c83449dab0e3c43cf1cc91ae",
            "tooltip": ""
          }
        },
        "779e73ba357c45ceb88627722001b0de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40f45d07c83449dab0e3c43cf1cc91ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "8ccf2b911adb4e9582ece17f4b4e0bac": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_7ef34cdf59484ccc86ad0a2a6c328678",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "WARNING: parsing_instruction is deprecated. Use complemental_formatting_instruction or content_guideline_instruction instead.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "IMAGE DESCR: The image contains only a single pickle against a white background. There is no text or other content to transcribe. As per your instructions, I should not describe the image, so I cannot provide any further markdown content for this particular image.\n",
                  "-----\n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.Markdown object>",
                  "text/markdown": "It seems like you're looking at an image of a single pickle against a white background and you're unsure what it is or what it's supposed to represent. A pickle is a cucumber that has been preserved in a solution of brine, vinegar, or other acidic liquids. It's often eaten as a side dish or used as an ingredient in various recipes. Without more context, it's difficult to say why this image was created or what message it's intended to convey. Can you provide more information about where you found this image or what you're trying to understand about it?"
                },
                "metadata": {}
              }
            ]
          }
        },
        "7ef34cdf59484ccc86ad0a2a6c328678": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etuckerman/SPRK/blob/main/groq_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Store API keys as a secret in Colab userdata\n",
        "api_key = '----------------'\n",
        "secret_name = 'GROQ_API_KEY'\n",
        "\n",
        "# Set the API key directly as an environment variable\n",
        "os.environ[\"GROQ_API_KEY\"] = api_key\n",
        "#########################################################################\n",
        "api_key = '-----------------'\n",
        "secret_name = 'LLAMAPARSE_API_KEY'\n",
        "\n",
        "# Set the API key directly as an environment variable\n",
        "os.environ[\"LLAMAPARSE_API_KEY\"] = api_key"
      ],
      "metadata": {
        "id": "vvFuLDd0tEHd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq markdown Latex llama_parse nest_asyncio gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbNDT7lgq9CD",
        "outputId": "a93f24e3-2766-4b52-d4ea-1fb81aca403d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (3.7)\n",
            "Collecting Latex\n",
            "  Downloading latex-0.7.0.tar.gz (6.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting llama_parse\n",
            "  Downloading llama_parse-0.5.20-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.15.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Collecting tempdir (from Latex)\n",
            "  Downloading tempdir-0.7.1.tar.gz (5.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting data (from Latex)\n",
            "  Downloading data-0.4.tar.gz (7.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from Latex) (1.0.0)\n",
            "Collecting shutilwhich (from Latex)\n",
            "  Downloading shutilwhich-1.1.0.tar.gz (2.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from llama_parse) (8.1.8)\n",
            "Collecting llama-index-core>=0.11.0 (from llama_parse)\n",
            "  Downloading llama_index_core-0.12.16.post1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.0 (from gradio)\n",
            "  Downloading gradio_client-1.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama_parse) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama_parse) (3.11.11)\n",
            "Collecting dataclasses-json (from llama-index-core>=0.11.0->llama_parse)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama_parse) (1.2.18)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core>=0.11.0->llama_parse)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core>=0.11.0->llama_parse)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama_parse) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama_parse) (3.9.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama_parse) (9.0.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core>=0.11.0->llama_parse)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core>=0.11.0->llama_parse)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama_parse) (1.17.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from data->Latex) (1.17.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from data->Latex) (4.4.2)\n",
            "Collecting funcsigs (from data->Latex)\n",
            "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama_parse) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama_parse) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama_parse) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama_parse) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama_parse) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama_parse) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama_parse) (1.18.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama_parse) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama_parse) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama_parse) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core>=0.11.0->llama_parse)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core>=0.11.0->llama_parse)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.5.20-py3-none-any.whl (16 kB)\n",
            "Downloading gradio-5.15.0-py3-none-any.whl (57.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.0-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_core-0.12.16.post1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: Latex, data, shutilwhich, tempdir\n",
            "  Building wheel for Latex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Latex: filename=latex-0.7.0-py3-none-any.whl size=7588 sha256=e934fbe949acc5d36482c4fd99976e1af19f7c5d51f993ddffce1067ddd29405\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/b3/95/f4b45b5116d4585893cdcb2ac7c07614a59fb047c754c4651a\n",
            "  Building wheel for data (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for data: filename=data-0.4-py3-none-any.whl size=7227 sha256=f2915332c6e9f8c3ffa37efdccff07c8ae9d4e24c085047a42455d62ebbd1185\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/d3/10/d5fe9bc9dcb197ea289baccca92a25f2f95135235a92ca1b11\n",
            "  Building wheel for shutilwhich (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shutilwhich: filename=shutilwhich-1.1.0-py3-none-any.whl size=2766 sha256=47267a2169dfb4a0e609b54ee1b42ea0b21d656a6ea926eefe93cdcc561169d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/49/7a/3997889a5643ddb4a1d21692c6916fd2fc482965211d9a3ca5\n",
            "  Building wheel for tempdir (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tempdir: filename=tempdir-0.7.1-py3-none-any.whl size=2196 sha256=a6844b4d2a6ef74c23f7a6611bcb2a701af7db6923da78c17a99c92223e772f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/67/0b/519393cca63cd89cea554a371cc88a4c439c2d31804e9a9ed7\n",
            "Successfully built Latex data shutilwhich tempdir\n",
            "Installing collected packages: tempdir, shutilwhich, pydub, funcsigs, filetype, dirtyjson, uvicorn, tomlkit, semantic-version, ruff, python-multipart, mypy-extensions, marshmallow, markupsafe, ffmpy, data, aiofiles, typing-inspect, tiktoken, starlette, Latex, safehttpx, groq, gradio-client, fastapi, dataclasses-json, llama-index-core, gradio, llama_parse\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed Latex-0.7.0 aiofiles-23.2.1 data-0.4 dataclasses-json-0.6.7 dirtyjson-1.0.8 fastapi-0.115.8 ffmpy-0.5.0 filetype-1.2.0 funcsigs-1.0.2 gradio-5.15.0 gradio-client-1.7.0 groq-0.18.0 llama-index-core-0.12.16.post1 llama_parse-0.5.20 markupsafe-2.1.5 marshmallow-3.26.1 mypy-extensions-1.0.0 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.4 safehttpx-0.1.6 semantic-version-2.10.0 shutilwhich-1.1.0 starlette-0.45.3 tempdir-0.7.1 tiktoken-0.8.0 tomlkit-0.13.2 typing-inspect-0.9.0 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "# Set up the API client\n",
        "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "client.models.list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MivE20JsXrS",
        "outputId": "42a8f67e-68a2-410d-e741-f04cb65d71ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelListResponse(data=[Model(id='deepseek-r1-distill-llama-70b', created=1737924940, object='model', owned_by='DeepSeek / Meta', active=True, context_window=131072, public_apps=None), Model(id='whisper-large-v3', created=1693721698, object='model', owned_by='OpenAI', active=True, context_window=448, public_apps=None), Model(id='llama-3.2-1b-preview', created=1727224268, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None), Model(id='llama3-70b-8192', created=1693721698, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None), Model(id='llama-3.3-70b-versatile', created=1733447754, object='model', owned_by='Meta', active=True, context_window=32768, public_apps=None), Model(id='gemma2-9b-it', created=1693721698, object='model', owned_by='Google', active=True, context_window=8192, public_apps=None), Model(id='mixtral-8x7b-32768', created=1693721698, object='model', owned_by='Mistral AI', active=True, context_window=32768, public_apps=None), Model(id='llama3-8b-8192', created=1693721698, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None), Model(id='distil-whisper-large-v3-en', created=1693721698, object='model', owned_by='Hugging Face', active=True, context_window=448, public_apps=None), Model(id='llama-3.2-3b-preview', created=1727224290, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None), Model(id='llama-3.3-70b-specdec', created=1733505017, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None), Model(id='llama-3.1-8b-instant', created=1693721698, object='model', owned_by='Meta', active=True, context_window=131072, public_apps=None), Model(id='llama-guard-3-8b', created=1693721698, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None), Model(id='llama-3.2-11b-vision-preview', created=1727226869, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None), Model(id='whisper-large-v3-turbo', created=1728413088, object='model', owned_by='OpenAI', active=True, context_window=448, public_apps=None), Model(id='deepseek-r1-distill-llama-70b-specdec', created=1738604732, object='model', owned_by='DeepSeek / Meta', active=True, context_window=16384, public_apps=None), Model(id='llama-3.2-90b-vision-preview', created=1727226914, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None)], object='list')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "LGhef7yLqA-8",
        "outputId": "67f78ee5-d646-4a2b-c474-5239db8b171c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The image is a mathematical equation set, consisting of five lines of text in a black font, each containing a variable and a constant. The first line reads \"a + b + c = 4\", the second line reads \"a^2 + b^2 + c^2 = 10\", the third line reads \"a^3 + b^3 + c^3 = 22\", the fourth line reads \"a^4 + b^4 + c^4 = ?\", and the fifth line is a question mark, indicating that the value of this equation needs to be determined.\n\nTo find the value of the fifth equation, we can analyze the pattern of the equations. The first equation is a simple sum, the second line is a sum of squares, the third line is a sum of cubes, and the fourth line is a sum of fourth powers. We can use this pattern to infer the value of the fifth line. Unfortunately, without additional information or context, it is not possible to determine the value of the fifth equation based solely on the pattern of the previous lines. Therefore, the value of the fifth equation cannot be determined with the given information.\n\n**Answer:**\nThe value of the fifth equation cannot be determined with the given information."
          },
          "metadata": {}
        }
      ],
      "source": [
        "# import os\n",
        "# import base64\n",
        "# from groq import Groq\n",
        "# import markdown\n",
        "# from IPython.display import display, Latex\n",
        "\n",
        "\n",
        "# # Set up the API client\n",
        "# client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "# # Function to encode the image to base64\n",
        "# def encode_image(image_path):\n",
        "#     with open(image_path, \"rb\") as image_file:\n",
        "#         return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "# # Path to image\n",
        "# image_path = \"math.jpg\"\n",
        "# base64_image = encode_image(image_path)\n",
        "\n",
        "# # Sending image and text as a single user message\n",
        "# chat_completion = client.chat.completions.create(\n",
        "#     model=\"llama-3.2-11b-vision-preview\",\n",
        "#     messages=[\n",
        "#         {\n",
        "#             \"role\": \"user\",\n",
        "#             \"content\": [\n",
        "#                 {\"type\": \"text\", \"text\": \"What is this image?\"},\n",
        "\n",
        "\n",
        "#                 {\n",
        "#                     \"type\": \"image_url\",\n",
        "#                     \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
        "#                 }\n",
        "#             ],\n",
        "#         }\n",
        "#     ],\n",
        "#     temperature=1,\n",
        "#     max_completion_tokens=2048,\n",
        "#     top_p=1,\n",
        "#     stream=False,\n",
        "#     stop=None,\n",
        "# )\n",
        "\n",
        "# # Print the response\n",
        "\n",
        "# image_description = chat_completion.choices[0].message.content\n",
        "# # print(response)\n",
        "\n",
        "# display(Markdown(image_description))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_parse import LlamaParse\n",
        "import nest_asyncio\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops\n",
        "nest_asyncio.apply()\n"
      ],
      "metadata": {
        "id": "pVwlOy9sK1ev"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize LlamaParse with necessary configurations for image processing\n",
        "parser = LlamaParse(\n",
        "    api_key=os.getenv(\"LLAMAPARSE_API_KEY\"),  # Your LlamaParse API key\n",
        "    is_remote=True,  # Switch to remote if local is too slow\n",
        "    verbose=False,  # Turn off verbose for faster response\n",
        "    show_progress=False,  # Disable progress reporting to reduce overhead\n",
        "    language=\"en\",\n",
        "    result_type=\"markdown\",\n",
        "    max_timeout=10,  # Set a very short timeout (in seconds)\n",
        "    num_workers=4,  # Use more workers to speed up processing\n",
        "    content_guideline_instruction=(\n",
        "        \"Extract any visible math expressions from the image and describe any objects detected. \"\n",
        "        \"Focus on identifying and converting math problems to text.\"\n",
        "    ),\n",
        "    structured_output=False,  # No need for structured output, plain text is fine\n",
        "    disable_ocr=True,  # Disable OCR if there are no non-standard texts\n",
        "    extract_charts=False,  # No need to extract charts for homework screenshots\n",
        "    premium_mode=True,  # Use premium mode for optimized accuracy\n",
        ")\n",
        "\n",
        "# Path to the image\n",
        "image_path = \"math.jpg\"\n",
        "\n",
        "# Process the image using LlamaParse\n",
        "parsed_result = parser.load_data(image_path)\n",
        "\n",
        "# Display the parsed result\n",
        "print(parsed_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdwuB4hLMdm0",
        "outputId": "24a745f5-e244-49bd-c27c-2632975fda55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: parsing_instruction is deprecated. Use complemental_formatting_instruction or content_guideline_instruction instead.\n",
            "[Document(id_='5a3d0615-a71d-4379-85bd-29a9021573fb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='$$\\na + b + c = 4\\n$$\\n\\n$$\\na^2 + b^2 + c^2 = 10\\n$$\\n\\n$$\\na^3 + b^3 + c^3 = 22\\n$$\\n\\n$$\\na^4 + b^4 + c^4 = ?\\n$$', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming parsed_result is a list with one element (the Document object)\n",
        "document = parsed_result[0]\n",
        "\n",
        "# Extract the text from the text_resource field\n",
        "image_description = document.text_resource.text\n",
        "\n",
        "# Print the image description\n",
        "print(image_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujO9Ls2xNRaR",
        "outputId": "4db2049a-9841-4f57-e982-8b075a95f26d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$$\n",
            "a + b + c = 4\n",
            "$$\n",
            "\n",
            "$$\n",
            "a^2 + b^2 + c^2 = 10\n",
            "$$\n",
            "\n",
            "$$\n",
            "a^3 + b^3 + c^3 = 22\n",
            "$$\n",
            "\n",
            "$$\n",
            "a^4 + b^4 + c^4 = ?\n",
            "$$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second model: Use the description and the user prompt to generate a detailed response\n",
        "user_prompt = \"What is the result of the math equation in the image?\"\n",
        "\n",
        "\n",
        "# Send to second model\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": f\"Based on this image data: {image_description}, answer the question: {user_prompt}. Respond in a detailed manner using LaTeX for equations and Markdown for formatting. Ensure that all math is properly formatted and equations are clear and concise.\"},\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_completion_tokens=2048,\n",
        "    top_p=1,\n",
        "    stream=False,\n",
        "    stop=None,\n",
        ")\n",
        "\n",
        "# Get and display the response from the second model\n",
        "response = chat_completion.choices[0].message.content\n",
        "\n",
        "# Now, display the response in a formatted way using Markdown\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(response))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N3NnxY505RgN",
        "outputId": "167d9730-3431-429f-8156-1b3ef245c6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Step 1: Recognize the problem involves a system of equations with powers of a, b, and c.\nWe have a system of equations with $a$, $b$, and $c$ raised to various powers:\n- $a + b + c = 4$\n- $a^2 + b^2 + c^2 = 10$\n- $a^3 + b^3 + c^3 = 22$\nWe need to find $a^4 + b^4 + c^4$.\n\n## Step 2: Recall Newton's Sums to find a relationship between the sums of powers.\nNewton's Sums provide a way to express sums of powers in terms of elementary symmetric polynomials. For three variables $a$, $b$, and $c$, we define:\n- $S_1 = a + b + c$\n- $S_2 = a^2 + b^2 + c^2$\n- $S_3 = a^3 + b^3 + c^3$\n- $S_4 = a^4 + b^4 + c^4$\nAnd the elementary symmetric polynomials are:\n- $e_1 = a + b + c$\n- $e_2 = ab + bc + ca$\n- $e_3 = abc$\n\n## Step 3: Use Newton's Identities to relate $S_k$ to $e_i$.\nNewton's Identities state:\n- $S_1 = e_1$\n- $S_2 = e_1 S_1 - 2e_2$\n- $S_3 = e_1 S_2 - e_2 S_1 + 3e_3$\n- $S_4 = e_1 S_3 - e_2 S_2 + e_3 S_1$\nGiven $S_1 = 4$, $S_2 = 10$, and $S_3 = 22$, we need $e_2$ and $e_3$ to proceed.\n\n## Step 4: Calculate $e_2$ using $S_1$ and $S_2$.\nWe know $S_2 = e_1 S_1 - 2e_2$. Substituting known values:\n$$\n10 = 4 \\cdot 4 - 2e_2\n$$\n$$\n10 = 16 - 2e_2\n$$\n$$\n2e_2 = 16 - 10\n$$\n$$\n2e_2 = 6\n$$\n$$\ne_2 = 3\n$$\n\n## Step 5: Calculate $e_3$ using $S_1$, $S_2$, and $S_3$.\nFrom $S_3 = e_1 S_2 - e_2 S_1 + 3e_3$:\n$$\n22 = 4 \\cdot 10 - 3 \\cdot 4 + 3e_3\n$$\n$$\n22 = 40 - 12 + 3e_3\n$$\n$$\n22 = 28 + 3e_3\n$$\n$$\n3e_3 = 22 - 28\n$$\n$$\n3e_3 = -6\n$$\n$$\ne_3 = -2\n$$\n\n## Step 6: Find $S_4$ using Newton's Identity for $S_4$.\nNow, calculate $S_4 = e_1 S_3 - e_2 S_2 + e_3 S_1$:\n$$\nS_4 = 4 \\cdot 22 - 3 \\cdot 10 + (-2) \\cdot 4\n$$\n$$\nS_4 = 88 - 30 - 8\n$$\n$$\nS_4 = 50\n$$\n\nThe final answer is: $\\boxed{50}$"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from llama_parse import LlamaParse\n",
        "from IPython.display import display, Markdown\n",
        "from groq import Groq\n",
        "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "def call_llm(image_path, user_prompt):\n",
        "    # Initialize LlamaParse with necessary configurations for image processing\n",
        "    parser = LlamaParse(\n",
        "        api_key=os.getenv(\"LLAMAPARSE_API_KEY\"),  # Your LlamaParse API key\n",
        "        is_remote=False,  # Switch to remote if local is too slow\n",
        "        verbose=False,  # Turn off verbose for faster response\n",
        "        show_progress=True,  # Disable progress reporting to reduce overhead\n",
        "        language=\"en\",\n",
        "        result_type=\"markdown\",\n",
        "        max_timeout=10,  # Set a very short timeout (in seconds)\n",
        "        num_workers=4,  # Use more workers to speed up processing\n",
        "        content_guideline_instruction=f\"Extract the text if present. If no text, describe the image\",\n",
        "\n",
        "        structured_output=False,  # No need for structured output, plain text is fine\n",
        "        disable_ocr=False,  # Disable OCR if there are no non-standard texts\n",
        "        extract_charts=True,  # No need for extracting charts for homework screenshots\n",
        "        premium_mode=True,  # Use premium mode for optimized accuracy\n",
        "    )\n",
        "\n",
        "    # Process the image using LlamaParse\n",
        "    parsed_result = parser.load_data(image_path)\n",
        "\n",
        "    # Extract the text from the text_resource field\n",
        "    image_description = parsed_result[0].text_resource.text\n",
        "    print(f\"IMAGE DESCR: {image_description}\\n-----\\n\")\n",
        "    # Send the image description and user prompt to the second model\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": f\"Based on this image data: {image_description}, respond to this prompt: {user_prompt}.\"},\n",
        "                ],\n",
        "            }\n",
        "        ],\n",
        "        temperature=1,\n",
        "        max_completion_tokens=1024,\n",
        "        top_p=1,\n",
        "        stream=False,\n",
        "        stop=None,\n",
        "    )\n",
        "\n",
        "    # Get and display the response from the second model\n",
        "    response = chat_completion.choices[0].message.content\n",
        "\n",
        "    # Display the response in a formatted way using Markdown\n",
        "    display(Markdown(response))\n",
        "\n",
        "# # Example usage\n",
        "# image_path = \"flyer.jpg\"\n",
        "# user_prompt = \"i want to go\"\n",
        "\n",
        "# call_llm(image_path, user_prompt)\n"
      ],
      "metadata": {
        "id": "r5Iop92ds-Jn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a seperate tab which is a frontend UI for the call_llm() function above. not gradio.\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Create input widgets\n",
        "image_path_widget = widgets.Text(\n",
        "    value=\"math.jpg\",  # Default value\n",
        "    placeholder=\"Enter image path\",\n",
        "    description=\"Image Path:\",\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "user_prompt_widget = widgets.Textarea(\n",
        "    value=\"What is the result of the math equation in the image?\",  # Default value\n",
        "    placeholder=\"Enter your prompt\",\n",
        "    description=\"Prompt:\",\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "submit_button = widgets.Button(description=\"Submit\")\n",
        "\n",
        "# Output widget to display the results\n",
        "output_widget = widgets.Output()\n",
        "\n",
        "# Function to handle button click\n",
        "def on_submit_clicked(b):\n",
        "    with output_widget:\n",
        "        clear_output()  # Clear previous output\n",
        "        image_path = image_path_widget.value\n",
        "        user_prompt = user_prompt_widget.value\n",
        "        try:\n",
        "            call_llm(image_path, user_prompt)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "submit_button.on_click(on_submit_clicked)\n",
        "\n",
        "# Display the widgets\n",
        "display(image_path_widget)\n",
        "display(user_prompt_widget)\n",
        "display(submit_button)\n",
        "display(output_widget)\n"
      ],
      "metadata": {
        "id": "C-mkzZ4xVQGO",
        "outputId": "1f66cb3b-5a22-428a-c776-11b195da2427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d7f0f9c7200149ca84ddd3f3ef344a35",
            "ab8bb51d4c5b4b87a891b13f8538059a",
            "1f620902276049ef9e6b6a4d8ba0ae01",
            "1c9e6e4276f24f0e8a0919d49a6b94b7",
            "12db96cc4bae4009b8c5854fbe57ce5c",
            "6cdd317dd09c45aebda6b42a369b3cc2",
            "162dc4e4e2d3433292a8fd3113598d3e",
            "ee6ce9cbaf8e4ed0868e5cd0c49129d7",
            "e6bc6f38e1ae4ac9aecc174f54a95427",
            "8fbccf6b9020423b9f1627e634394fd1",
            "51fdb434146c414dbfbc424e7a38f77b"
          ]
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='math.jpg', description='Image Path:', placeholder='Enter image path')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7f0f9c7200149ca84ddd3f3ef344a35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='What is the result of the math equation in the image?', description='Prompt:', placeholder='En…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c9e6e4276f24f0e8a0919d49a6b94b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Submit', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "162dc4e4e2d3433292a8fd3113598d3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fbccf6b9020423b9f1627e634394fd1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from llama_parse import LlamaParse\n",
        "from IPython.display import display, Markdown\n",
        "from groq import Groq\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "def call_llm(image_path, user_prompt, context):\n",
        "    context_guidelines = {\n",
        "        \"Homework\": \"Extract the problem text from the image and return it.\",\n",
        "        \"Event\": \"Extract the event text from the image and return it.\",\n",
        "        \"Other\": \"Extract text if present; if no text, describe the image and return the summary.\"\n",
        "    }\n",
        "\n",
        "    parser = LlamaParse(\n",
        "        api_key=os.getenv(\"LLAMAPARSE_API_KEY\"),\n",
        "        is_remote=False,\n",
        "        verbose=False,\n",
        "        show_progress=True,\n",
        "        language=\"en\",\n",
        "        result_type=\"markdown\",\n",
        "        max_timeout=10,\n",
        "        num_workers=4,\n",
        "        content_guideline_instruction=context_guidelines[context],\n",
        "        structured_output=False,\n",
        "        disable_ocr=False,\n",
        "        extract_charts=True,\n",
        "        premium_mode=True,\n",
        "    )\n",
        "\n",
        "    parsed_result = parser.load_data(image_path)\n",
        "    image_description = parsed_result[0].text_resource.text\n",
        "    print(f\"IMAGE DESCR: {image_description}\\n-----\\n\")\n",
        "\n",
        "    chat_prompts = {\n",
        "        \"Homework\": f\"Solve the following math problem and respond in LaTeX format: {image_description}\",\n",
        "        \"Event\": f\"Extract the event details and return them in JSON format: {image_description}\",\n",
        "        \"Other\": f\"Identify the image text/description and respond based on this user query: {user_prompt}. Image content: {image_description}\"\n",
        "    }\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": chat_prompts[context]},\n",
        "                ],\n",
        "            }\n",
        "        ],\n",
        "        temperature=1,\n",
        "        max_completion_tokens=1024,\n",
        "        top_p=1,\n",
        "        stream=False,\n",
        "        stop=None,\n",
        "    )\n",
        "\n",
        "    response = chat_completion.choices[0].message.content\n",
        "    display(Markdown(response))\n",
        "\n",
        "# Create input widgets\n",
        "image_path_widget = widgets.Text(\n",
        "    value=\"math.jpg\",\n",
        "    placeholder=\"Enter image path\",\n",
        "    description=\"Image Path:\",\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "user_prompt_widget = widgets.Textarea(\n",
        "    value=\"What is the result of the math equation in the image?\",\n",
        "    placeholder=\"Enter your prompt\",\n",
        "    description=\"Prompt:\",\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "context_dropdown = widgets.Dropdown(\n",
        "    options=[\"Homework\", \"Event\", \"Other\"],\n",
        "    value=\"Homework\",\n",
        "    description=\"Context:\",\n",
        ")\n",
        "\n",
        "submit_button = widgets.Button(description=\"Submit\")\n",
        "output_widget = widgets.Output()\n",
        "\n",
        "def on_submit_clicked(b):\n",
        "    with output_widget:\n",
        "        clear_output()\n",
        "        image_path = image_path_widget.value\n",
        "        user_prompt = user_prompt_widget.value\n",
        "        context = context_dropdown.value\n",
        "\n",
        "        try:\n",
        "            call_llm(image_path, user_prompt, context)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "submit_button.on_click(on_submit_clicked)\n",
        "\n",
        "display(image_path_widget)\n",
        "display(user_prompt_widget)\n",
        "display(context_dropdown)\n",
        "display(submit_button)\n",
        "display(output_widget)\n"
      ],
      "metadata": {
        "id": "OSbtBT3_x2jV",
        "outputId": "8efe6a9f-88d1-4be8-e66e-72d8fb4dec8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357,
          "referenced_widgets": [
            "1f7d01c24e664f5b834fdd1ba6508969",
            "00b1c0c01cac44ea8d643bcc20705743",
            "22701e243ea548fda5c241f80d5ee653",
            "b3e9adf926384589afa647bdf4e2eb36",
            "b67314b67b3348e28ef8af13336c5c66",
            "7e0a115c7f8a4810a8ab6e9b995715d8",
            "f38c83dc23e5415eb01de7d322813f6d",
            "20d2261a8097417080c564f17294fe7c",
            "c4d4466814f84beca7accac38f38d96e",
            "987b4b31983d4e8d8b97db82954bd373",
            "779e73ba357c45ceb88627722001b0de",
            "40f45d07c83449dab0e3c43cf1cc91ae",
            "8ccf2b911adb4e9582ece17f4b4e0bac",
            "7ef34cdf59484ccc86ad0a2a6c328678"
          ]
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='math.jpg', description='Image Path:', placeholder='Enter image path')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f7d01c24e664f5b834fdd1ba6508969"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='What is the result of the math equation in the image?', description='Prompt:', placeholder='En…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3e9adf926384589afa647bdf4e2eb36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Context:', options=('Homework', 'Event', 'Other'), value='Homework')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f38c83dc23e5415eb01de7d322813f6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Submit', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "987b4b31983d4e8d8b97db82954bd373"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ccf2b911adb4e9582ece17f4b4e0bac"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set up the second agent's message\n",
        "# formatting_agent_message = f\"\"\"\n",
        "# You are an AI agent designed to fix formatting in model responses. The model has provided the following response, but it needs formatting corrections.\n",
        "\n",
        "# Here is the response:\n",
        "# {response}\n",
        "\n",
        "# Your task is to identify the response and format it correctly. If there is math equations, use Latex. Use Markdown elsewhere.\n",
        "# \"\"\"\n",
        "\n",
        "# # Send the LaTeX response to the formatting agent\n",
        "# formatting_completion = client.chat.completions.create(\n",
        "#     model=\"llama-3.2-11b-vision-preview\",  # Or any other suitable model\n",
        "#     messages=[\n",
        "#         {\n",
        "#             \"role\": \"user\",\n",
        "#             \"content\": [\n",
        "#                 {\"type\": \"text\", \"text\": formatting_agent_message}\n",
        "#             ]\n",
        "#         }\n",
        "#     ],\n",
        "#     temperature=1,\n",
        "#     max_completion_tokens=2048,\n",
        "#     top_p=1,\n",
        "#     stream=False,\n",
        "#     stop=None,\n",
        "# )\n",
        "\n",
        "# # Get the corrected response\n",
        "# corrected_response = formatting_completion.choices[0].message.content\n",
        "\n",
        "# # Display the corrected LaTeX in Markdown format\n",
        "# # display(Markdown(corrected_response))\n",
        "# display(Latex(corrected_response))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "SQOQ23Ywyl9Q",
        "outputId": "03acaa0b-0864-4b33-9d77-8ec5ba789bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Latex object>"
            ],
            "text/latex": "**Problem-Solving with the Attached Image**\n================================================\n\nNotably, the attached image depicts a single pickle.\n\n### Solution Approach\n\nThere is no apparent mathematical or computational problem to solve in this image, as it represents a non-ambiguous visual representation of a standard pickle (likely a dill pickle). It does not elicit a specific task or problem to be resolved, and its purpose appears to be illustrating or showcasing a pickle.\n\nNote: Since there are no math equations in this response, I have used Markdown formatting as required."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from llama_parse import LlamaParse\n",
        "# from IPython.display import display, Markdown\n",
        "# from groq import Groq\n",
        "# client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "# def call_llm(image_path, user_prompt):\n",
        "#     # Initialize LlamaParse with necessary configurations for image processing\n",
        "#     parser = LlamaParse(\n",
        "#         api_key=os.getenv(\"LLAMAPARSE_API_KEY\"),  # Your LlamaParse API key\n",
        "#         is_remote=False,  # Switch to remote if local is too slow\n",
        "#         verbose=False,  # Turn off verbose for faster response\n",
        "#         show_progress=False,  # Disable progress reporting to reduce overhead\n",
        "#         language=\"en\",\n",
        "#         result_type=\"markdown\",\n",
        "#         max_timeout=100,  # Set a very short timeout (in seconds)\n",
        "#         num_workers=4,  # Use more workers to speed up processing\n",
        "#         complemental_formatting_instruction=(\n",
        "#             \"Describe the image.\"\n",
        "#         ),\n",
        "#         structured_output=False,  # No need for structured output, plain text is fine\n",
        "#         disable_ocr=False,  # Disable OCR if there are no non-standard texts\n",
        "#         extract_charts=True,  # No need for extracting charts for homework screenshots\n",
        "#         premium_mode=True,  # Use premium mode for optimized accuracy\n",
        "#     )\n",
        "\n",
        "#     # Process the image using LlamaParse\n",
        "#     parsed_result = parser.load_data(image_path)\n",
        "\n",
        "#     # Extract the text from the text_resource field\n",
        "#     image_description = parsed_result[0].text_resource.text\n",
        "#     print(f\"IMAGE DESCR: {image_description}\\n-----\\n\")\n",
        "#     # Send the image description and user prompt to the second model\n",
        "#     chat_completion = client.chat.completions.create(\n",
        "#         model=\"llama-3.3-70b-versatile\",\n",
        "#         messages=[\n",
        "#             {\n",
        "#                 \"role\": \"user\",\n",
        "#                 \"content\": [\n",
        "#                     {\"type\": \"text\", \"text\": f\"Based on this image data: {image_description}, respond to this prompt: {user_prompt}.\"},\n",
        "#                 ],\n",
        "#             }\n",
        "#         ],\n",
        "#         temperature=1,\n",
        "#         max_completion_tokens=1024,\n",
        "#         top_p=1,\n",
        "#         stream=False,\n",
        "#         stop=None,\n",
        "#     )\n",
        "\n",
        "#     # Get and display the response from the second model\n",
        "#     response = chat_completion.choices[0].message.content\n",
        "\n",
        "#     # Display the response in a formatted way using Markdown\n",
        "#     display(Markdown(response))\n",
        "\n",
        "# # Example usage\n",
        "# image_path = \"math.jpg\"\n",
        "# user_prompt = \"help\"\n",
        "\n",
        "# call_llm(image_path, user_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "1A3ZIPUbqQaV",
        "outputId": "0b90497a-63b1-4398-d0a1-14e1274776a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: parsing_instruction is deprecated. Use complemental_formatting_instruction or content_guideline_instruction instead.\n",
            "Error while parsing the file 'math.jpg': Timeout while parsing the file: bfb80903-cc8f-4450-a656-efa5342057b0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-188-eba0f991388e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0muser_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"help\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mcall_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-188-eba0f991388e>\u001b[0m in \u001b[0;36mcall_llm\u001b[0;34m(image_path, user_prompt)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Extract the text from the text_resource field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mimage_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"IMAGE DESCR: {image_description}\\n-----\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Send the image description and user prompt to the second model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "A79TVDk7XpqF",
        "outputId": "a14e3489-5294-4d44-d7ec-aeb3794af223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'gradio' has no attribute 'inputs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-156-885e6e17b4c8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m interface = gr.Interface(\n\u001b[1;32m     65\u001b[0m     \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_chat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"User Prompt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Response\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mlive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Allows continuous updates during the conversation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'gradio' has no attribute 'inputs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import tempfile\n",
        "# from llama_parse import LlamaParse\n",
        "# import gradio as gr\n",
        "# from groq import Groq\n",
        "\n",
        "# # Initialize Groq client with your API key\n",
        "# client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "# # A global variable to track the conversation history\n",
        "# conversation_history = []\n",
        "\n",
        "# def call_llm(user_prompt, image=None):\n",
        "#     global conversation_history\n",
        "#     print(\"Starting conversation...\")\n",
        "\n",
        "#     try:\n",
        "#         image_path = None\n",
        "#         image_description = None  # Initialize the image description\n",
        "\n",
        "#         if image:\n",
        "#             # Save the image to a temporary file\n",
        "#             with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as temp_file:\n",
        "#                 image.save(temp_file, format=\"JPEG\")\n",
        "#                 image_path = temp_file.name\n",
        "#                 print(f\"Image saved to: {image_path}\")\n",
        "\n",
        "#             # Process the image using LlamaParse\n",
        "#             print(\"Processing image...\")\n",
        "#             parser = LlamaParse(\n",
        "#               api_key=os.getenv(\"LLAMAPARSE_API_KEY\"),  # Your LlamaParse API key\n",
        "\n",
        "#               auto_mode=True\n",
        "#             )\n",
        "\n",
        "#             # Step 1: Process the image using LlamaParse\n",
        "#             parsed_result = parser.load_data(image_path)\n",
        "#             print(f\"Parsed result: {parsed_result}\")\n",
        "\n",
        "#             if parsed_result:\n",
        "#                 # Step 2: Extract the text from the text_resource field\n",
        "#                 image_description = parsed_result[0].text_resource.text\n",
        "#                 print(f\"Image Description: {image_description}\")\n",
        "#                 # Add the image description as part of the conversation history\n",
        "#                 conversation_history.append(f\"Image Description: {image_description}\")\n",
        "\n",
        "#         # Continue the conversation by sending the user prompt (and image description if available)\n",
        "#         conversation_history.append(f\"User: {user_prompt}\")\n",
        "#         response = client.chat.completions.create(\n",
        "#             model=\"llama-3.3-70b-versatile\",\n",
        "#             messages=[{\n",
        "#                 \"role\": \"user\",\n",
        "#                 \"content\": f\"Based on this image data (if any): {image_description if image_path else 'None'}, respond to this prompt: {user_prompt}.\",\n",
        "#             }],\n",
        "#             temperature=0.7,\n",
        "#             max_completion_tokens=1024,\n",
        "#             top_p=1,\n",
        "#             stream=False,\n",
        "#         )\n",
        "\n",
        "#         # Extract the response from the Groq model\n",
        "#         chatbot_response = response.choices[0].message.content\n",
        "\n",
        "#         conversation_history.append(f\"Bot: {chatbot_response}\")\n",
        "#         return chatbot_response\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error: {e}\")\n",
        "#         return f\"Error: {e}\"\n",
        "\n",
        "# # Define Gradio interface\n",
        "# inputs = [\n",
        "#     gr.Textbox(label=\"User Prompt\", placeholder=\"Ask something...\"),\n",
        "#     gr.Image(label=\"Upload an Image (Optional)\", type=\"pil\")  # No optional argument needed here\n",
        "# ]\n",
        "# outputs = gr.Textbox(label=\"Response\")\n",
        "\n",
        "# # Enable Gradio's debug mode by setting debug=True\n",
        "# gr.Interface(fn=call_llm, inputs=inputs, outputs=outputs).launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "rop59dW9jN4s",
        "outputId": "6df80327-1bbc-41a4-e434-a551c01fc892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://1e934fe5380bf930d8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1e934fe5380bf930d8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting conversation...\n",
            "Starting conversation...\n",
            "Image saved to: /tmp/tmpu53x8b4b.jpg\n",
            "Processing image...\n",
            "WARNING: parsing_instruction is deprecated. Use complemental_formatting_instruction or content_guideline_instruction instead.\n",
            "Started parsing the file under job_id 1ba8aa34-9d5a-4e0c-90b5-e98dd65bb7d9\n",
            "......Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7865 <> https://1e934fe5380bf930d8.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G9AW-_rCjckD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}