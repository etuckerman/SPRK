{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuB/NmOAASnL0Re/qILQGD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d7f0f9c7200149ca84ddd3f3ef344a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Image Path:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ab8bb51d4c5b4b87a891b13f8538059a",
            "placeholder": "Enter image path",
            "style": "IPY_MODEL_1f620902276049ef9e6b6a4d8ba0ae01",
            "value": "flyer.jpg"
          }
        },
        "ab8bb51d4c5b4b87a891b13f8538059a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f620902276049ef9e6b6a4d8ba0ae01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c9e6e4276f24f0e8a0919d49a6b94b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Prompt:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_12db96cc4bae4009b8c5854fbe57ce5c",
            "placeholder": "Enter your prompt",
            "rows": null,
            "style": "IPY_MODEL_6cdd317dd09c45aebda6b42a369b3cc2",
            "value": "thoughts?"
          }
        },
        "12db96cc4bae4009b8c5854fbe57ce5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cdd317dd09c45aebda6b42a369b3cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "162dc4e4e2d3433292a8fd3113598d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Submit",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ee6ce9cbaf8e4ed0868e5cd0c49129d7",
            "style": "IPY_MODEL_e6bc6f38e1ae4ac9aecc174f54a95427",
            "tooltip": ""
          }
        },
        "ee6ce9cbaf8e4ed0868e5cd0c49129d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6bc6f38e1ae4ac9aecc174f54a95427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "8fbccf6b9020423b9f1627e634394fd1": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_51fdb434146c414dbfbc424e7a38f77b",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "WARNING: parsing_instruction is deprecated. Use complemental_formatting_instruction or content_guideline_instruction instead.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "IMAGE DESCR: # LEARN FRENCH\n",
                  "\n",
                  "## FRE 2200 FRENCH 3-001\n",
                  "\n",
                  "### SPRING 2025\n",
                  "\n",
                  "LAST BUT NOT LEAST COURSE TO MASTER\n",
                  "THE BASICS OF FRENCH LANGUAGE!\n",
                  "\n",
                  "TOPICS COVERED: SOCIAL AND\n",
                  "CULTURAL VALUES, IMMIGRATION,\n",
                  "THE ENVIRONMENT and more...\n",
                  "\n",
                  "\\+ MULTIMEDIA, MUSIC & A FRENCH FILM.\n",
                  "\n",
                  "### GATEWAY COURSE TO ALL UPPER-LEVEL FRENCH COURSES INCLUDING:\n",
                  "\n",
                  "- MINOR IN FRENCH\n",
                  "- MAJOR OR DOUBLE MAJOR IN WORLD\n",
                  "  LANGUAGES-FRENCH CONCENTRATION\n",
                  "\n",
                  "### WHO, WHEN, WHERE, HOW?\n",
                  "\n",
                  "MW 11:00AM- 12:15PM\n",
                  "SOC: 347\n",
                  "CRN: #13910\n",
                  "\n",
                  "### CONTACT INFO\n",
                  "\n",
                  "savonas@usf.edu\n",
                  "World Languages Department\n",
                  "\n",
                  "----\n",
                  "\n",
                  "UNIVERSITY of\n",
                  "SOUTH FLORIDA\n",
                  "College of Arts & Sciences\n",
                  "-----\n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.Markdown object>",
                  "text/markdown": "The provided text appears to be a course description for a French language class, FRE 2200, at the University of South Florida. Here are some thoughts based on the information:\n\n1. **Comprehensive curriculum**: The course covers a range of topics, including social and cultural values, immigration, and the environment, which suggests a well-rounded and engaging learning experience.\n2. **Multimedia and cultural elements**: The inclusion of multimedia, music, and a French film will likely make the course more enjoyable and help students connect with the language on a deeper level.\n3. **Importance of the course**: As a gateway course to upper-level French classes, this course seems crucial for students interested in pursuing a minor or major in French or World Languages with a French concentration.\n4. **Accessibility**: The course schedule (MW 11:00AM-12:15PM) and location (SOC: 347) are clearly stated, making it easy for students to plan their schedules.\n5. **Support and resources**: The contact information for the instructor (savonas@usf.edu) and the World Languages Department provides students with a clear point of contact for questions or concerns.\n6. **Institutional context**: The course is part of the University of South Florida's College of Arts & Sciences, which suggests that the university values language education and cultural diversity.\n\nOverall, the course seems to offer a solid foundation in French language and culture, with a good balance of academic and cultural content. It also appears to be well-supported by the university and the instructor, which can help students succeed in their language learning journey."
                },
                "metadata": {}
              }
            ]
          }
        },
        "51fdb434146c414dbfbc424e7a38f77b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f351bc23db294f07aad3a39c60d81e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Image Path:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6fb7671b63fb48db9fdb748184ef31ef",
            "placeholder": "Enter image path",
            "style": "IPY_MODEL_a0c61a968d334402bc1d13232fabaa92",
            "value": "/content/AST309C_KFinkelstein_46800 (3).pdf"
          }
        },
        "6fb7671b63fb48db9fdb748184ef31ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0c61a968d334402bc1d13232fabaa92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13a915b9d97d4022bfefe751a5b8c326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Prompt:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_bad14eb2538b434192ddb2c116b7adcd",
            "placeholder": "Enter your prompt",
            "rows": null,
            "style": "IPY_MODEL_7525752253e34a0386269cf7c5bb4782",
            "value": "whos my teacher"
          }
        },
        "bad14eb2538b434192ddb2c116b7adcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7525752253e34a0386269cf7c5bb4782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e80355e2ad32450ba8cf7afd4f69e5e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Homework",
              "Event",
              "Other"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Context:",
            "description_tooltip": null,
            "disabled": false,
            "index": 2,
            "layout": "IPY_MODEL_c47d03880682458ca60e145b5c51f1cb",
            "style": "IPY_MODEL_28c8c16da43f40c5be413ef1822455d4"
          }
        },
        "c47d03880682458ca60e145b5c51f1cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28c8c16da43f40c5be413ef1822455d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a40c3c9fb2d4dcf9b0c14afe4613142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Submit",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_5843a8c7577b4b4e8357f78552add637",
            "style": "IPY_MODEL_95307d8003704f50986e1efef692c893",
            "tooltip": ""
          }
        },
        "5843a8c7577b4b4e8357f78552add637": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95307d8003704f50986e1efef692c893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f5e6dfcf1a244ea898d2a1a3f6eab182": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_f6cb1cd9410e40e88e3dda42ac17a5d4",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Started parsing the file under job_id 5aecc7e6-f57f-474f-9a73-b26c4cf07623\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "IMAGE DESCR: AST 309C\n",
                  "Dr. Keely Finkelstein\n",
                  "Spring 2024\n",
                  "# THE BIRTH OF STARS AND PLANETS\n",
                  "Meeting Times: TTh 11am - 12:15pm | Room: WEL 3.502 | Unique Number: 46800\n",
                  "\n",
                  "# How can I contact my professor or TAs?\n",
                  "**Professor:**\n",
                  "Dr. Keely Finkelstein\n",
                  "Dept. of Astronomy\n",
                  "Office: PMA 16.206\n",
                  "Email:\n",
                  "keelyf@astro.as.utexas.edu\n",
                  "\n",
                  "**Instructor Weekly Help Sessions:** TBD and/or by appt. in Dr. Finkelstein's office, PMA 16.206 or on zoom.\n",
                  "\n",
                  "**TA:** Vignesh Sankaran\n",
                  "Email: vignesh.s@utexas.edu\n",
                  "Weekly Help Session hours: TBD\n",
                  "\n",
                  "**TA:** Prudhvi Sai Pachchipulusu\n",
                  "Email: prudhvisai535@utexas.edu\n",
                  "Weekly Help Session hours: TBD\n",
                  "\n",
                  "# What is this course about?\n",
                  "This course will present a study of how stars & planets form. Stars form out of giant clouds of gas and dust, locked in a battle between gravity and pressure. Gravity eventually wins and stars and planets form in the resulting disk of material. We will study this process including results from state of the art extrasolar planet searches, discussing implications on the formation of our own solar system.\n",
                  "\n",
                  "AST 309C is a one semester class on the specific topic of star and planet formation. AST 309C meets one of the Natural Sciences Part I Core Requirements.\n",
                  "\n",
                  "# Course Learning Objectives:\n",
                  "Core course themes and learning objectives are centered around the following, and by the end of the semester students will be able to:\n",
                  "\n",
                  "*   Understand and describe science as a process.\n",
                  "*   Use of critical thinking and quantitative reasoning skills, and gain an understanding of the importance of them in the broader context of the scientific process and scientific theory.\n",
                  "*   Gain a broad understanding of the nature, scope, and evolution of the Universe, and where the Earth and Solar System fit in.\n",
                  "*   Describe how physical systems change and evolve with time.\n",
                  "*   Use models and observations to explain processes related to star formation, planet formation, and solar systems.\n",
                  "*   Evaluate and Interpret key scientific points from public scientific sources, such as popular press articles.\n",
                  "AST 309C\n",
                  "Page 1\n",
                  "-----\n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.Markdown object>",
                  "text/markdown": "Your teacher for the course AST 309C, \"The Birth of Stars and Planets,\" is Dr. Keely Finkelstein. You can contact her at her office (PMA 16.206) or through email at keelyf@astro.as.utexas.edu. Additionally, she has two teaching assistants, Vignesh Sankaran (vignesh.s@utexas.edu) and Prudhvi Sai Pachchipulusu (prudhvisai535@utexas.edu), who are also available for help."
                },
                "metadata": {}
              }
            ]
          }
        },
        "f6cb1cd9410e40e88e3dda42ac17a5d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etuckerman/SPRK/blob/main/groq_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Store API keys as a secret in Colab userdata\n",
        "api_key = '----------------'\n",
        "secret_name = 'GROQ_API_KEY'\n",
        "\n",
        "# Set the API key directly as an environment variable\n",
        "os.environ[\"GROQ_API_KEY\"] = api_key\n",
        "#########################################################################\n",
        "api_key = '-----------------'\n",
        "secret_name = 'LLAMAPARSE_API_KEY'\n",
        "\n",
        "# Set the API key directly as an environment variable\n",
        "os.environ[\"LLAMAPARSE_API_KEY\"] = api_key"
      ],
      "metadata": {
        "id": "vvFuLDd0tEHd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq markdown Latex llama_parse nest_asyncio gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbNDT7lgq9CD",
        "outputId": "d4f59c87-9eed-4c7f-e359-c5b2b0ec02fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (3.7)\n",
            "Collecting Latex\n",
            "  Downloading latex-0.7.0.tar.gz (6.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting llama_parse\n",
            "  Downloading llama_parse-0.6.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.16.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Collecting tempdir (from Latex)\n",
            "  Downloading tempdir-0.7.1.tar.gz (5.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting data (from Latex)\n",
            "  Downloading data-0.4.tar.gz (7.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from Latex) (1.0.0)\n",
            "Collecting shutilwhich (from Latex)\n",
            "  Downloading shutilwhich-1.1.0.tar.gz (2.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting llama-cloud-services>=0.6.1 (from llama_parse)\n",
            "  Downloading llama_cloud_services-0.6.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.0 (from gradio)\n",
            "  Downloading gradio_client-1.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.1->llama_parse) (8.1.8)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.11 (from llama-cloud-services>=0.6.1->llama_parse)\n",
            "  Downloading llama_cloud-0.1.12-py3-none-any.whl.metadata (851 bytes)\n",
            "Collecting llama-index-core>=0.11.0 (from llama-cloud-services>=0.6.1->llama_parse)\n",
            "  Downloading llama_index_core-0.12.17-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.1->llama_parse)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from data->Latex) (1.17.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from data->Latex) (4.4.2)\n",
            "Collecting funcsigs (from data->Latex)\n",
            "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (2.0.38)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (3.11.12)\n",
            "Collecting dataclasses-json (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (1.2.18)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (3.9.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (9.0.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (1.17.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (1.18.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (2024.11.6)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama_parse)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.1-py3-none-any.whl (4.8 kB)\n",
            "Downloading gradio-5.16.0-py3-none-any.whl (62.2 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.0-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_cloud_services-0.6.1-py3-none-any.whl (22 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading llama_cloud-0.1.12-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_core-0.12.17-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: Latex, data, shutilwhich, tempdir\n",
            "  Building wheel for Latex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Latex: filename=latex-0.7.0-py3-none-any.whl size=7588 sha256=b6ea7b43572766c65c5220a04cf3329d3caf19c6c1128d4a6e9d128a3fe80f4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/b3/95/f4b45b5116d4585893cdcb2ac7c07614a59fb047c754c4651a\n",
            "  Building wheel for data (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for data: filename=data-0.4-py3-none-any.whl size=7227 sha256=739ad9459ab0a4b5e33e211160eb43c757ac116d0ee5b0ae591a7dfb89dcedc4\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/d3/10/d5fe9bc9dcb197ea289baccca92a25f2f95135235a92ca1b11\n",
            "  Building wheel for shutilwhich (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shutilwhich: filename=shutilwhich-1.1.0-py3-none-any.whl size=2766 sha256=bbd848f7420d9616ebf751b0aa6a970679db76e29d5450d77e348a34eb54fb29\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/49/7a/3997889a5643ddb4a1d21692c6916fd2fc482965211d9a3ca5\n",
            "  Building wheel for tempdir (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tempdir: filename=tempdir-0.7.1-py3-none-any.whl size=2196 sha256=9b2e7dcfaa40e9a11282a58ab7fe03b103897e67c8ebeaf1d8247a5da19c0b06\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/67/0b/519393cca63cd89cea554a371cc88a4c439c2d31804e9a9ed7\n",
            "Successfully built Latex data shutilwhich tempdir\n",
            "Installing collected packages: tempdir, shutilwhich, pydub, funcsigs, filetype, dirtyjson, uvicorn, tomlkit, semantic-version, ruff, python-multipart, python-dotenv, mypy-extensions, marshmallow, markupsafe, ffmpy, data, aiofiles, typing-inspect, tiktoken, starlette, Latex, safehttpx, llama-cloud, groq, gradio-client, fastapi, dataclasses-json, llama-index-core, gradio, llama-cloud-services, llama_parse\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed Latex-0.7.0 aiofiles-23.2.1 data-0.4 dataclasses-json-0.6.7 dirtyjson-1.0.8 fastapi-0.115.8 ffmpy-0.5.0 filetype-1.2.0 funcsigs-1.0.2 gradio-5.16.0 gradio-client-1.7.0 groq-0.18.0 llama-cloud-0.1.12 llama-cloud-services-0.6.1 llama-index-core-0.12.17 llama_parse-0.6.1 markupsafe-2.1.5 marshmallow-3.26.1 mypy-extensions-1.0.0 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.20 ruff-0.9.6 safehttpx-0.1.6 semantic-version-2.10.0 shutilwhich-1.1.0 starlette-0.45.3 tempdir-0.7.1 tiktoken-0.9.0 tomlkit-0.13.2 typing-inspect-0.9.0 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "# Set up the API client\n",
        "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "client.models.list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MivE20JsXrS",
        "outputId": "a851ca89-b027-42ce-cfd8-d5442ffa8881"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelListResponse(data=[Model(id='distil-whisper-large-v3-en', created=1693721698, object='model', owned_by='Hugging Face', active=True, context_window=448, public_apps=None), Model(id='llama-guard-3-8b', created=1693721698, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None), Model(id='deepseek-r1-distill-qwen-32b', created=1738891590, object='model', owned_by='DeepSeek / Alibaba Cloud', active=True, context_window=131072, public_apps=None), Model(id='deepseek-r1-distill-llama-70b-specdec', created=1738604732, object='model', owned_by='DeepSeek / Meta', active=True, context_window=16384, public_apps=None), Model(id='gemma2-9b-it', created=1693721698, object='model', owned_by='Google', active=True, context_window=8192, public_apps=None), Model(id='deepseek-r1-distill-llama-70b', created=1737924940, object='model', owned_by='DeepSeek / Meta', active=True, context_window=131072, public_apps=None), Model(id='whisper-large-v3-turbo', created=1728413088, object='model', owned_by='OpenAI', active=True, context_window=448, public_apps=None), Model(id='llama-3.2-3b-preview', created=1727224290, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None), Model(id='llama-3.1-8b-instant', created=1693721698, object='model', owned_by='Meta', active=True, context_window=131072, public_apps=None), Model(id='qwen-2.5-32b', created=1738789898, object='model', owned_by='Alibaba Cloud', active=True, context_window=131072, public_apps=None), Model(id='llama-3.2-11b-vision-preview', created=1727226869, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None), Model(id='llama-3.2-90b-vision-preview', created=1727226914, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None), Model(id='llama-3.2-1b-preview', created=1727224268, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None), Model(id='llama-3.3-70b-versatile', created=1733447754, object='model', owned_by='Meta', active=True, context_window=32768, public_apps=None), Model(id='qwen-2.5-coder-32b', created=1739494572, object='model', owned_by='Alibaba Cloud', active=True, context_window=131072, public_apps=None), Model(id='llama3-8b-8192', created=1693721698, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None), Model(id='llama3-70b-8192', created=1693721698, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None), Model(id='llama-3.3-70b-specdec', created=1733505017, object='model', owned_by='Meta', active=True, context_window=8192, public_apps=None), Model(id='whisper-large-v3', created=1693721698, object='model', owned_by='OpenAI', active=True, context_window=448, public_apps=None), Model(id='mixtral-8x7b-32768', created=1693721698, object='model', owned_by='Mistral AI', active=True, context_window=32768, public_apps=None)], object='list')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "LGhef7yLqA-8",
        "outputId": "67f78ee5-d646-4a2b-c474-5239db8b171c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The image is a mathematical equation set, consisting of five lines of text in a black font, each containing a variable and a constant. The first line reads \"a + b + c = 4\", the second line reads \"a^2 + b^2 + c^2 = 10\", the third line reads \"a^3 + b^3 + c^3 = 22\", the fourth line reads \"a^4 + b^4 + c^4 = ?\", and the fifth line is a question mark, indicating that the value of this equation needs to be determined.\n\nTo find the value of the fifth equation, we can analyze the pattern of the equations. The first equation is a simple sum, the second line is a sum of squares, the third line is a sum of cubes, and the fourth line is a sum of fourth powers. We can use this pattern to infer the value of the fifth line. Unfortunately, without additional information or context, it is not possible to determine the value of the fifth equation based solely on the pattern of the previous lines. Therefore, the value of the fifth equation cannot be determined with the given information.\n\n**Answer:**\nThe value of the fifth equation cannot be determined with the given information."
          },
          "metadata": {}
        }
      ],
      "source": [
        "# import os\n",
        "# import base64\n",
        "# from groq import Groq\n",
        "# import markdown\n",
        "# from IPython.display import display, Latex\n",
        "\n",
        "\n",
        "# # Set up the API client\n",
        "# client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "# # Function to encode the image to base64\n",
        "# def encode_image(image_path):\n",
        "#     with open(image_path, \"rb\") as image_file:\n",
        "#         return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "# # Path to image\n",
        "# image_path = \"math.jpg\"\n",
        "# base64_image = encode_image(image_path)\n",
        "\n",
        "# # Sending image and text as a single user message\n",
        "# chat_completion = client.chat.completions.create(\n",
        "#     model=\"llama-3.2-11b-vision-preview\",\n",
        "#     messages=[\n",
        "#         {\n",
        "#             \"role\": \"user\",\n",
        "#             \"content\": [\n",
        "#                 {\"type\": \"text\", \"text\": \"What is this image?\"},\n",
        "\n",
        "\n",
        "#                 {\n",
        "#                     \"type\": \"image_url\",\n",
        "#                     \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
        "#                 }\n",
        "#             ],\n",
        "#         }\n",
        "#     ],\n",
        "#     temperature=1,\n",
        "#     max_completion_tokens=2048,\n",
        "#     top_p=1,\n",
        "#     stream=False,\n",
        "#     stop=None,\n",
        "# )\n",
        "\n",
        "# # Print the response\n",
        "\n",
        "# image_description = chat_completion.choices[0].message.content\n",
        "# # print(response)\n",
        "\n",
        "# display(Markdown(image_description))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_parse import LlamaParse\n",
        "import nest_asyncio\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops\n",
        "nest_asyncio.apply()\n"
      ],
      "metadata": {
        "id": "pVwlOy9sK1ev"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize LlamaParse with necessary configurations for image processing\n",
        "parser = LlamaParse(\n",
        "    api_key=os.getenv(\"LLAMAPARSE_API_KEY\"),  # Your LlamaParse API key\n",
        "    is_remote=True,  # Switch to remote if local is too slow\n",
        "    verbose=False,  # Turn off verbose for faster response\n",
        "    show_progress=False,  # Disable progress reporting to reduce overhead\n",
        "    language=\"en\",\n",
        "    result_type=\"markdown\",\n",
        "    max_timeout=10,  # Set a very short timeout (in seconds)\n",
        "    num_workers=4,  # Use more workers to speed up processing\n",
        "    content_guideline_instruction=(\n",
        "        \"Extract any visible math expressions from the image and describe any objects detected. \"\n",
        "        \"Focus on identifying and converting math problems to text.\"\n",
        "    ),\n",
        "    structured_output=False,  # No need for structured output, plain text is fine\n",
        "    disable_ocr=True,  # Disable OCR if there are no non-standard texts\n",
        "    extract_charts=False,  # No need to extract charts for homework screenshots\n",
        "    premium_mode=True,  # Use premium mode for optimized accuracy\n",
        ")\n",
        "\n",
        "# Path to the image\n",
        "image_path = \"math.jpg\"\n",
        "\n",
        "# Process the image using LlamaParse\n",
        "parsed_result = parser.load_data(image_path)\n",
        "\n",
        "# Display the parsed result\n",
        "print(parsed_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdwuB4hLMdm0",
        "outputId": "24a745f5-e244-49bd-c27c-2632975fda55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: parsing_instruction is deprecated. Use complemental_formatting_instruction or content_guideline_instruction instead.\n",
            "[Document(id_='5a3d0615-a71d-4379-85bd-29a9021573fb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='$$\\na + b + c = 4\\n$$\\n\\n$$\\na^2 + b^2 + c^2 = 10\\n$$\\n\\n$$\\na^3 + b^3 + c^3 = 22\\n$$\\n\\n$$\\na^4 + b^4 + c^4 = ?\\n$$', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming parsed_result is a list with one element (the Document object)\n",
        "document = parsed_result[0]\n",
        "\n",
        "# Extract the text from the text_resource field\n",
        "image_description = document.text_resource.text\n",
        "\n",
        "# Print the image description\n",
        "print(image_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujO9Ls2xNRaR",
        "outputId": "4db2049a-9841-4f57-e982-8b075a95f26d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$$\n",
            "a + b + c = 4\n",
            "$$\n",
            "\n",
            "$$\n",
            "a^2 + b^2 + c^2 = 10\n",
            "$$\n",
            "\n",
            "$$\n",
            "a^3 + b^3 + c^3 = 22\n",
            "$$\n",
            "\n",
            "$$\n",
            "a^4 + b^4 + c^4 = ?\n",
            "$$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second model: Use the description and the user prompt to generate a detailed response\n",
        "user_prompt = \"What is the result of the math equation in the image?\"\n",
        "\n",
        "\n",
        "# Send to second model\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": f\"Based on this image data: {image_description}, answer the question: {user_prompt}. Respond in a detailed manner using LaTeX for equations and Markdown for formatting. Ensure that all math is properly formatted and equations are clear and concise.\"},\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_completion_tokens=2048,\n",
        "    top_p=1,\n",
        "    stream=False,\n",
        "    stop=None,\n",
        ")\n",
        "\n",
        "# Get and display the response from the second model\n",
        "response = chat_completion.choices[0].message.content\n",
        "\n",
        "# Now, display the response in a formatted way using Markdown\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(response))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N3NnxY505RgN",
        "outputId": "167d9730-3431-429f-8156-1b3ef245c6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Step 1: Recognize the problem involves a system of equations with powers of a, b, and c.\nWe have a system of equations with $a$, $b$, and $c$ raised to various powers:\n- $a + b + c = 4$\n- $a^2 + b^2 + c^2 = 10$\n- $a^3 + b^3 + c^3 = 22$\nWe need to find $a^4 + b^4 + c^4$.\n\n## Step 2: Recall Newton's Sums to find a relationship between the sums of powers.\nNewton's Sums provide a way to express sums of powers in terms of elementary symmetric polynomials. For three variables $a$, $b$, and $c$, we define:\n- $S_1 = a + b + c$\n- $S_2 = a^2 + b^2 + c^2$\n- $S_3 = a^3 + b^3 + c^3$\n- $S_4 = a^4 + b^4 + c^4$\nAnd the elementary symmetric polynomials are:\n- $e_1 = a + b + c$\n- $e_2 = ab + bc + ca$\n- $e_3 = abc$\n\n## Step 3: Use Newton's Identities to relate $S_k$ to $e_i$.\nNewton's Identities state:\n- $S_1 = e_1$\n- $S_2 = e_1 S_1 - 2e_2$\n- $S_3 = e_1 S_2 - e_2 S_1 + 3e_3$\n- $S_4 = e_1 S_3 - e_2 S_2 + e_3 S_1$\nGiven $S_1 = 4$, $S_2 = 10$, and $S_3 = 22$, we need $e_2$ and $e_3$ to proceed.\n\n## Step 4: Calculate $e_2$ using $S_1$ and $S_2$.\nWe know $S_2 = e_1 S_1 - 2e_2$. Substituting known values:\n$$\n10 = 4 \\cdot 4 - 2e_2\n$$\n$$\n10 = 16 - 2e_2\n$$\n$$\n2e_2 = 16 - 10\n$$\n$$\n2e_2 = 6\n$$\n$$\ne_2 = 3\n$$\n\n## Step 5: Calculate $e_3$ using $S_1$, $S_2$, and $S_3$.\nFrom $S_3 = e_1 S_2 - e_2 S_1 + 3e_3$:\n$$\n22 = 4 \\cdot 10 - 3 \\cdot 4 + 3e_3\n$$\n$$\n22 = 40 - 12 + 3e_3\n$$\n$$\n22 = 28 + 3e_3\n$$\n$$\n3e_3 = 22 - 28\n$$\n$$\n3e_3 = -6\n$$\n$$\ne_3 = -2\n$$\n\n## Step 6: Find $S_4$ using Newton's Identity for $S_4$.\nNow, calculate $S_4 = e_1 S_3 - e_2 S_2 + e_3 S_1$:\n$$\nS_4 = 4 \\cdot 22 - 3 \\cdot 10 + (-2) \\cdot 4\n$$\n$$\nS_4 = 88 - 30 - 8\n$$\n$$\nS_4 = 50\n$$\n\nThe final answer is: $\\boxed{50}$"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from llama_parse import LlamaParse\n",
        "from IPython.display import display, Markdown\n",
        "from groq import Groq\n",
        "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "def call_llm(image_path, user_prompt):\n",
        "    # Initialize LlamaParse with necessary configurations for image processing\n",
        "    parser = LlamaParse(\n",
        "        api_key=os.getenv(\"LLAMAPARSE_API_KEY\"),  # Your LlamaParse API key\n",
        "        is_remote=False,  # Switch to remote if local is too slow\n",
        "        verbose=False,  # Turn off verbose for faster response\n",
        "        show_progress=True,  # Disable progress reporting to reduce overhead\n",
        "        language=\"en\",\n",
        "        result_type=\"markdown\",\n",
        "        max_timeout=10,  # Set a very short timeout (in seconds)\n",
        "        num_workers=4,  # Use more workers to speed up processing\n",
        "        content_guideline_instruction=f\"Extract the text if present. If no text, describe the image\",\n",
        "\n",
        "        structured_output=False,  # No need for structured output, plain text is fine\n",
        "        disable_ocr=False,  # Disable OCR if there are no non-standard texts\n",
        "        extract_charts=True,  # No need for extracting charts for homework screenshots\n",
        "        premium_mode=True,  # Use premium mode for optimized accuracy\n",
        "    )\n",
        "\n",
        "    # Process the image using LlamaParse\n",
        "    parsed_result = parser.load_data(image_path)\n",
        "\n",
        "    # Extract the text from the text_resource field\n",
        "    image_description = parsed_result[0].text_resource.text\n",
        "    print(f\"IMAGE DESCR: {image_description}\\n-----\\n\")\n",
        "    # Send the image description and user prompt to the second model\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": f\"Based on this image data: {image_description}, respond to this prompt: {user_prompt}.\"},\n",
        "                ],\n",
        "            }\n",
        "        ],\n",
        "        temperature=1,\n",
        "        max_completion_tokens=1024,\n",
        "        top_p=1,\n",
        "        stream=False,\n",
        "        stop=None,\n",
        "    )\n",
        "\n",
        "    # Get and display the response from the second model\n",
        "    response = chat_completion.choices[0].message.content\n",
        "\n",
        "    # Display the response in a formatted way using Markdown\n",
        "    display(Markdown(response))\n",
        "\n",
        "# # Example usage\n",
        "# image_path = \"flyer.jpg\"\n",
        "# user_prompt = \"i want to go\"\n",
        "\n",
        "# call_llm(image_path, user_prompt)\n"
      ],
      "metadata": {
        "id": "r5Iop92ds-Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a seperate tab which is a frontend UI for the call_llm() function above. not gradio.\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Create input widgets\n",
        "image_path_widget = widgets.Text(\n",
        "    value=\"math.jpg\",  # Default value\n",
        "    placeholder=\"Enter image path\",\n",
        "    description=\"Image Path:\",\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "user_prompt_widget = widgets.Textarea(\n",
        "    value=\"What is the result of the math equation in the image?\",  # Default value\n",
        "    placeholder=\"Enter your prompt\",\n",
        "    description=\"Prompt:\",\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "submit_button = widgets.Button(description=\"Submit\")\n",
        "\n",
        "# Output widget to display the results\n",
        "output_widget = widgets.Output()\n",
        "\n",
        "# Function to handle button click\n",
        "def on_submit_clicked(b):\n",
        "    with output_widget:\n",
        "        clear_output()  # Clear previous output\n",
        "        image_path = image_path_widget.value\n",
        "        user_prompt = user_prompt_widget.value\n",
        "        try:\n",
        "            call_llm(image_path, user_prompt)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "submit_button.on_click(on_submit_clicked)\n",
        "\n",
        "# Display the widgets\n",
        "display(image_path_widget)\n",
        "display(user_prompt_widget)\n",
        "display(submit_button)\n",
        "display(output_widget)\n"
      ],
      "metadata": {
        "id": "C-mkzZ4xVQGO",
        "outputId": "1f66cb3b-5a22-428a-c776-11b195da2427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d7f0f9c7200149ca84ddd3f3ef344a35",
            "ab8bb51d4c5b4b87a891b13f8538059a",
            "1f620902276049ef9e6b6a4d8ba0ae01",
            "1c9e6e4276f24f0e8a0919d49a6b94b7",
            "12db96cc4bae4009b8c5854fbe57ce5c",
            "6cdd317dd09c45aebda6b42a369b3cc2",
            "162dc4e4e2d3433292a8fd3113598d3e",
            "ee6ce9cbaf8e4ed0868e5cd0c49129d7",
            "e6bc6f38e1ae4ac9aecc174f54a95427",
            "8fbccf6b9020423b9f1627e634394fd1",
            "51fdb434146c414dbfbc424e7a38f77b"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='math.jpg', description='Image Path:', placeholder='Enter image path')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7f0f9c7200149ca84ddd3f3ef344a35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='What is the result of the math equation in the image?', description='Prompt:', placeholder='En"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c9e6e4276f24f0e8a0919d49a6b94b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Submit', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "162dc4e4e2d3433292a8fd3113598d3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fbccf6b9020423b9f1627e634394fd1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from llama_parse import LlamaParse\n",
        "from IPython.display import display, Markdown\n",
        "from groq import Groq\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "def call_llm(image_path, user_prompt, context):\n",
        "    context_guidelines = {\n",
        "        \"Homework\": \"Extract the problem text from the image and return it.\",\n",
        "        \"Event\": \"Extract the event text from the image and return it.\",\n",
        "        \"Other\": \"Extract text if present; if no text, describe the image and return the summary.\"\n",
        "    }\n",
        "\n",
        "    # parser = LlamaParse(\n",
        "    #     api_key=os.getenv(\"LLAMAPARSE_API_KEY\"),\n",
        "    #     is_remote=False,\n",
        "    #     verbose=False,\n",
        "    #     show_progress=True,\n",
        "    #     language=\"en\",\n",
        "    #     result_type=\"markdown\",\n",
        "    #     max_timeout=10,\n",
        "    #     num_workers=4,\n",
        "    #     content_guideline_instruction=context_guidelines[context],\n",
        "    #     structured_output=False,\n",
        "    #     disable_ocr=False,\n",
        "    #     extract_charts=True,\n",
        "    #     premium_mode=True,\n",
        "    # )\n",
        "    parser = LlamaParse(\n",
        "      api_key=os.getenv(\"LLAMAPARSE_API_KEY\"),\n",
        "      result_type=\"markdown\",\n",
        "      use_vendor_multimodal_model=True,\n",
        "      vendor_multimodal_model_name=\"gemini-2.0-flash-001\",\n",
        "      invalidate_cache=True,\n",
        "      content_guideline_instruction=context_guidelines[context],\n",
        "    )\n",
        "\n",
        "    parsed_result = parser.load_data(image_path)\n",
        "    image_description = parsed_result[0].text_resource.text\n",
        "    print(f\"IMAGE DESCR: {image_description}\\n-----\\n\")\n",
        "\n",
        "    chat_prompts = {\n",
        "        \"Homework\": f\"Solve the following math problem and respond in LaTeX format: {image_description}\",\n",
        "        \"Event\": f\"Extract the event details and return them in JSON format: {image_description}\",\n",
        "        \"Other\": f\"Identify the image text/description and respond based on this user query: {user_prompt}. Image content: {image_description}\"\n",
        "    }\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": chat_prompts[context]},\n",
        "                ],\n",
        "            }\n",
        "        ],\n",
        "        temperature=1,\n",
        "        max_completion_tokens=1024,\n",
        "        top_p=1,\n",
        "        stream=False,\n",
        "        stop=None,\n",
        "    )\n",
        "\n",
        "    response = chat_completion.choices[0].message.content\n",
        "    display(Markdown(response))\n",
        "\n",
        "# Create input widgets\n",
        "image_path_widget = widgets.Text(\n",
        "    value=\"math.jpg\",\n",
        "    placeholder=\"Enter image path\",\n",
        "    description=\"Image Path:\",\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "user_prompt_widget = widgets.Textarea(\n",
        "    value=\"What is the result of the math equation in the image?\",\n",
        "    placeholder=\"Enter your prompt\",\n",
        "    description=\"Prompt:\",\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "context_dropdown = widgets.Dropdown(\n",
        "    options=[\"Homework\", \"Event\", \"Other\"],\n",
        "    value=\"Homework\",\n",
        "    description=\"Context:\",\n",
        ")\n",
        "\n",
        "submit_button = widgets.Button(description=\"Submit\")\n",
        "output_widget = widgets.Output()\n",
        "\n",
        "def on_submit_clicked(b):\n",
        "    with output_widget:\n",
        "        clear_output()\n",
        "        image_path = image_path_widget.value\n",
        "        user_prompt = user_prompt_widget.value\n",
        "        context = context_dropdown.value\n",
        "\n",
        "        try:\n",
        "            call_llm(image_path, user_prompt, context)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "submit_button.on_click(on_submit_clicked)\n",
        "\n",
        "display(image_path_widget)\n",
        "display(user_prompt_widget)\n",
        "display(context_dropdown)\n",
        "display(submit_button)\n",
        "display(output_widget)\n"
      ],
      "metadata": {
        "id": "OSbtBT3_x2jV",
        "outputId": "08dd1982-0849-4ca2-f27a-e5436e5e8413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f351bc23db294f07aad3a39c60d81e53",
            "6fb7671b63fb48db9fdb748184ef31ef",
            "a0c61a968d334402bc1d13232fabaa92",
            "13a915b9d97d4022bfefe751a5b8c326",
            "bad14eb2538b434192ddb2c116b7adcd",
            "7525752253e34a0386269cf7c5bb4782",
            "e80355e2ad32450ba8cf7afd4f69e5e0",
            "c47d03880682458ca60e145b5c51f1cb",
            "28c8c16da43f40c5be413ef1822455d4",
            "0a40c3c9fb2d4dcf9b0c14afe4613142",
            "5843a8c7577b4b4e8357f78552add637",
            "95307d8003704f50986e1efef692c893",
            "f5e6dfcf1a244ea898d2a1a3f6eab182",
            "f6cb1cd9410e40e88e3dda42ac17a5d4"
          ]
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='math.jpg', description='Image Path:', placeholder='Enter image path')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f351bc23db294f07aad3a39c60d81e53"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='What is the result of the math equation in the image?', description='Prompt:', placeholder='En"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13a915b9d97d4022bfefe751a5b8c326"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Context:', options=('Homework', 'Event', 'Other'), value='Homework')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e80355e2ad32450ba8cf7afd4f69e5e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Submit', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a40c3c9fb2d4dcf9b0c14afe4613142"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5e6dfcf1a244ea898d2a1a3f6eab182"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set up the second agent's message\n",
        "# formatting_agent_message = f\"\"\"\n",
        "# You are an AI agent designed to fix formatting in model responses. The model has provided the following response, but it needs formatting corrections.\n",
        "\n",
        "# Here is the response:\n",
        "# {response}\n",
        "\n",
        "# Your task is to identify the response and format it correctly. If there is math equations, use Latex. Use Markdown elsewhere.\n",
        "# \"\"\"\n",
        "\n",
        "# # Send the LaTeX response to the formatting agent\n",
        "# formatting_completion = client.chat.completions.create(\n",
        "#     model=\"llama-3.2-11b-vision-preview\",  # Or any other suitable model\n",
        "#     messages=[\n",
        "#         {\n",
        "#             \"role\": \"user\",\n",
        "#             \"content\": [\n",
        "#                 {\"type\": \"text\", \"text\": formatting_agent_message}\n",
        "#             ]\n",
        "#         }\n",
        "#     ],\n",
        "#     temperature=1,\n",
        "#     max_completion_tokens=2048,\n",
        "#     top_p=1,\n",
        "#     stream=False,\n",
        "#     stop=None,\n",
        "# )\n",
        "\n",
        "# # Get the corrected response\n",
        "# corrected_response = formatting_completion.choices[0].message.content\n",
        "\n",
        "# # Display the corrected LaTeX in Markdown format\n",
        "# # display(Markdown(corrected_response))\n",
        "# display(Latex(corrected_response))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "SQOQ23Ywyl9Q",
        "outputId": "03acaa0b-0864-4b33-9d77-8ec5ba789bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Latex object>"
            ],
            "text/latex": "**Problem-Solving with the Attached Image**\n================================================\n\nNotably, the attached image depicts a single pickle.\n\n### Solution Approach\n\nThere is no apparent mathematical or computational problem to solve in this image, as it represents a non-ambiguous visual representation of a standard pickle (likely a dill pickle). It does not elicit a specific task or problem to be resolved, and its purpose appears to be illustrating or showcasing a pickle.\n\nNote: Since there are no math equations in this response, I have used Markdown formatting as required."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from llama_parse import LlamaParse\n",
        "# from IPython.display import display, Markdown\n",
        "# from groq import Groq\n",
        "# client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "# def call_llm(image_path, user_prompt):\n",
        "#     # Initialize LlamaParse with necessary configurations for image processing\n",
        "#     parser = LlamaParse(\n",
        "#         api_key=os.getenv(\"LLAMAPARSE_API_KEY\"),  # Your LlamaParse API key\n",
        "#         is_remote=False,  # Switch to remote if local is too slow\n",
        "#         verbose=False,  # Turn off verbose for faster response\n",
        "#         show_progress=False,  # Disable progress reporting to reduce overhead\n",
        "#         language=\"en\",\n",
        "#         result_type=\"markdown\",\n",
        "#         max_timeout=100,  # Set a very short timeout (in seconds)\n",
        "#         num_workers=4,  # Use more workers to speed up processing\n",
        "#         complemental_formatting_instruction=(\n",
        "#             \"Describe the image.\"\n",
        "#         ),\n",
        "#         structured_output=False,  # No need for structured output, plain text is fine\n",
        "#         disable_ocr=False,  # Disable OCR if there are no non-standard texts\n",
        "#         extract_charts=True,  # No need for extracting charts for homework screenshots\n",
        "#         premium_mode=True,  # Use premium mode for optimized accuracy\n",
        "#     )\n",
        "\n",
        "#     # Process the image using LlamaParse\n",
        "#     parsed_result = parser.load_data(image_path)\n",
        "\n",
        "#     # Extract the text from the text_resource field\n",
        "#     image_description = parsed_result[0].text_resource.text\n",
        "#     print(f\"IMAGE DESCR: {image_description}\\n-----\\n\")\n",
        "#     # Send the image description and user prompt to the second model\n",
        "#     chat_completion = client.chat.completions.create(\n",
        "#         model=\"llama-3.3-70b-versatile\",\n",
        "#         messages=[\n",
        "#             {\n",
        "#                 \"role\": \"user\",\n",
        "#                 \"content\": [\n",
        "#                     {\"type\": \"text\", \"text\": f\"Based on this image data: {image_description}, respond to this prompt: {user_prompt}.\"},\n",
        "#                 ],\n",
        "#             }\n",
        "#         ],\n",
        "#         temperature=1,\n",
        "#         max_completion_tokens=1024,\n",
        "#         top_p=1,\n",
        "#         stream=False,\n",
        "#         stop=None,\n",
        "#     )\n",
        "\n",
        "#     # Get and display the response from the second model\n",
        "#     response = chat_completion.choices[0].message.content\n",
        "\n",
        "#     # Display the response in a formatted way using Markdown\n",
        "#     display(Markdown(response))\n",
        "\n",
        "# # Example usage\n",
        "# image_path = \"math.jpg\"\n",
        "# user_prompt = \"help\"\n",
        "\n",
        "# call_llm(image_path, user_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "1A3ZIPUbqQaV",
        "outputId": "0b90497a-63b1-4398-d0a1-14e1274776a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: parsing_instruction is deprecated. Use complemental_formatting_instruction or content_guideline_instruction instead.\n",
            "Error while parsing the file 'math.jpg': Timeout while parsing the file: bfb80903-cc8f-4450-a656-efa5342057b0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-188-eba0f991388e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0muser_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"help\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mcall_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-188-eba0f991388e>\u001b[0m in \u001b[0;36mcall_llm\u001b[0;34m(image_path, user_prompt)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Extract the text from the text_resource field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mimage_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"IMAGE DESCR: {image_description}\\n-----\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Send the image description and user prompt to the second model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "A79TVDk7XpqF",
        "outputId": "a14e3489-5294-4d44-d7ec-aeb3794af223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'gradio' has no attribute 'inputs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-156-885e6e17b4c8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m interface = gr.Interface(\n\u001b[1;32m     65\u001b[0m     \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_chat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"User Prompt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Response\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mlive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Allows continuous updates during the conversation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'gradio' has no attribute 'inputs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import tempfile\n",
        "# from llama_parse import LlamaParse\n",
        "# import gradio as gr\n",
        "# from groq import Groq\n",
        "\n",
        "# # Initialize Groq client with your API key\n",
        "# client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "# # A global variable to track the conversation history\n",
        "# conversation_history = []\n",
        "\n",
        "# def call_llm(user_prompt, image=None):\n",
        "#     global conversation_history\n",
        "#     print(\"Starting conversation...\")\n",
        "\n",
        "#     try:\n",
        "#         image_path = None\n",
        "#         image_description = None  # Initialize the image description\n",
        "\n",
        "#         if image:\n",
        "#             # Save the image to a temporary file\n",
        "#             with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as temp_file:\n",
        "#                 image.save(temp_file, format=\"JPEG\")\n",
        "#                 image_path = temp_file.name\n",
        "#                 print(f\"Image saved to: {image_path}\")\n",
        "\n",
        "#             # Process the image using LlamaParse\n",
        "#             print(\"Processing image...\")\n",
        "#             parser = LlamaParse(\n",
        "#               api_key=os.getenv(\"LLAMAPARSE_API_KEY\"),  # Your LlamaParse API key\n",
        "\n",
        "#               auto_mode=True\n",
        "#             )\n",
        "\n",
        "#             # Step 1: Process the image using LlamaParse\n",
        "#             parsed_result = parser.load_data(image_path)\n",
        "#             print(f\"Parsed result: {parsed_result}\")\n",
        "\n",
        "#             if parsed_result:\n",
        "#                 # Step 2: Extract the text from the text_resource field\n",
        "#                 image_description = parsed_result[0].text_resource.text\n",
        "#                 print(f\"Image Description: {image_description}\")\n",
        "#                 # Add the image description as part of the conversation history\n",
        "#                 conversation_history.append(f\"Image Description: {image_description}\")\n",
        "\n",
        "#         # Continue the conversation by sending the user prompt (and image description if available)\n",
        "#         conversation_history.append(f\"User: {user_prompt}\")\n",
        "#         response = client.chat.completions.create(\n",
        "#             model=\"llama-3.3-70b-versatile\",\n",
        "#             messages=[{\n",
        "#                 \"role\": \"user\",\n",
        "#                 \"content\": f\"Based on this image data (if any): {image_description if image_path else 'None'}, respond to this prompt: {user_prompt}.\",\n",
        "#             }],\n",
        "#             temperature=0.7,\n",
        "#             max_completion_tokens=1024,\n",
        "#             top_p=1,\n",
        "#             stream=False,\n",
        "#         )\n",
        "\n",
        "#         # Extract the response from the Groq model\n",
        "#         chatbot_response = response.choices[0].message.content\n",
        "\n",
        "#         conversation_history.append(f\"Bot: {chatbot_response}\")\n",
        "#         return chatbot_response\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error: {e}\")\n",
        "#         return f\"Error: {e}\"\n",
        "\n",
        "# # Define Gradio interface\n",
        "# inputs = [\n",
        "#     gr.Textbox(label=\"User Prompt\", placeholder=\"Ask something...\"),\n",
        "#     gr.Image(label=\"Upload an Image (Optional)\", type=\"pil\")  # No optional argument needed here\n",
        "# ]\n",
        "# outputs = gr.Textbox(label=\"Response\")\n",
        "\n",
        "# # Enable Gradio's debug mode by setting debug=True\n",
        "# gr.Interface(fn=call_llm, inputs=inputs, outputs=outputs).launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "rop59dW9jN4s",
        "outputId": "6df80327-1bbc-41a4-e434-a551c01fc892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://1e934fe5380bf930d8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1e934fe5380bf930d8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting conversation...\n",
            "Starting conversation...\n",
            "Image saved to: /tmp/tmpu53x8b4b.jpg\n",
            "Processing image...\n",
            "WARNING: parsing_instruction is deprecated. Use complemental_formatting_instruction or content_guideline_instruction instead.\n",
            "Started parsing the file under job_id 1ba8aa34-9d5a-4e0c-90b5-e98dd65bb7d9\n",
            "......Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7865 <> https://1e934fe5380bf930d8.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G9AW-_rCjckD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}